{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m EMAS_TB \u001b[38;5;241m=\u001b[39m \u001b[43memas\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTONGUE_225-x[cm]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTONGUE_225-y[cm]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTONGUE_225-z[cm]\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      2\u001b[0m EMAS_TT \u001b[38;5;241m=\u001b[39m emas[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTONGUE_115-x[cm]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTONGUE_115-y[cm]\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTONGUE_115-z[cm]\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "pd.read_pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! The *paule* package is still in alpha. To download pretrained weights for the PAULE model, which is defined in `paule.paule.Paule`, you can invoke `paule.util.download_pretrained_weights()`.\n",
      "Version of the VocalTractLab library: \"API 2.6.0quantling Dec 22 2022\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from paule import util\n",
    "import os\n",
    "import fasttext.util\n",
    "import math\n",
    "#fasttext.util.download_model('de', if_exists='ignore')  # English\n",
    "FASTTEXT_EMBEDDINGS = fasttext.load_model('cc.de.300.bin')\n",
    "PATH = '/home/bob/AndreWorkland/articubench'\n",
    "example_tiny = pd.read_pickle(os.path.join(PATH, 'articubench/data/tiny.pkl'))\n",
    "test_small = pd.read_pickle(os.path.join(PATH, 'articubench/data/common_voice_geco_words_test_subset_slim_prot4.pkl'))\n",
    "test_jahalt = pd.read_pickle(os.path.join(PATH, 'articubench/data/ja_halt.pickle'))\n",
    "small_df_geco = pd.DataFrame()\n",
    "small_df_geco['file'] = test_small['file_name']\n",
    "small_df_geco['label'] = test_small['label']\n",
    "small_df_geco['target_semantic_vector'] = test_small['vector']\n",
    "small_df_geco['target_sig'] = test_small['wav_rec']\n",
    "small_df_geco['target_sr'] = test_small['sr_rec']\n",
    "small_df_geco['len_cp'] = test_small['cp_norm'].apply(lambda x: len(x))\n",
    "small_df_geco['reference_cp'] = test_small['cp_norm'].apply(lambda x: util.inv_normalize_cp(x)) #hier cp_norm oder inverses cp_norm?\n",
    "small_df_geco['reference_tongue_height'] = None\n",
    "small_df_geco['reference_ema'] = None\n",
    "\n",
    "small_df_jahalt = pd.DataFrame()\n",
    "small_df_jahalt['file'] = [str(i) + '_jahalt.pkl' for i in range(len(test_jahalt))]\n",
    "small_df_jahalt['label'] = test_jahalt['Word']\n",
    "small_df_jahalt['target_semantic_vector'] = test_jahalt['Word'].apply(lambda x: np.double(FASTTEXT_EMBEDDINGS.get_word_vector(x)))\n",
    "small_df_jahalt['target_sig'] = test_jahalt['Signal']\n",
    "small_df_jahalt['target_sr'] = test_jahalt['SampleRate'] #SampleRate is 22050 for ja_halt\n",
    "small_df_jahalt['len_cp'] = test_jahalt.apply(lambda row: int(2 * math.ceil(44100 / 220 * len(row['Signal']) / row['SampleRate'])), axis=1) #TODO: Wielang sind die cps? Hab als quickfix einfach 402 * len(sig_rec) / sig_sr genommen und dann auf n채chste even int geceilt\n",
    "small_df_jahalt['reference_cp'] = None\n",
    "small_df_jahalt['reference_tongue_height'] = None\n",
    "small_df_jahalt['reference_ema'] = None #TODO: EMA Daten einf체gen\n",
    "small_df_jahalt['reference_ema_TT'] = None #TODO: EMA Daten einf체gen\n",
    "small_df_jahalt['reference_ema_TB'] = None #TODO: EMA Daten einf체gen\n",
    "test_jahalt.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext.util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#FASTTEXT_EMBEDDINGS = fasttext.load_model('/home/bob/AndreWorkland/articubench/cc.de.300.bin')\n",
    "\n",
    "LABEL_VECTORS = pd.read_pickle('/home/bob/AndreWorkland/articubench/articubench/data/lexical_embedding_vectors.pkl')\n",
    "# Create new entries for \"ja\" and \"halt\"\n",
    "new_entries = pd.DataFrame({\n",
    "    'label': ['ja', 'halt'],\n",
    "    'vector': [np.round(FASTTEXT_EMBEDDINGS.get_word_vector('ja'),4), np.round(FASTTEXT_EMBEDDINGS.get_word_vector('halt'),4)],\n",
    "    'phones': [['j', 'a'], ['h', 'a', 'l', 't']],\n",
    "    'durations': [[0.13, 0.11], [0.0966, 0.063, 0.0766, 0.085]]\n",
    "})\n",
    "\n",
    "# Append the new entries to LABEL_VECTORS\n",
    "LABEL_VECTORS = pd.concat([LABEL_VECTORS, new_entries], ignore_index=True)\n",
    "LABEL_VECTORS.to_pickle('/home/bob/AndreWorkland/articubench/articubench/data/lexical_embedding_vectors2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! The *articubench* package is still in alpha and the package   does not contain all the files you need to execute the functions defined here. To download model weights (around 50 MB) run `articubench.util.download_pretrained_weights()` once.\n",
      "Version of the VocalTractLab library: \"API 2.5.2quantling Apr 26 2022\"\n",
      "WARNING! The *paule* package is still in alpha. To download pretrained weights for the PAULE model, which is defined in `paule.paule.Paule`, you can invoke `paule.util.download_pretrained_weights()`.\n",
      "Version of the VocalTractLab library: \"API 2.6.0quantling Dec 22 2022\"\n",
      "pretrained_models exist already. Skip download. Path is /home/bob/miniconda3/lib/python3.12/site-packages/paule/pretrained_models\n",
      "Version of pretrained weights is \"common voice 20240306\"\n",
      "Version of pretrained weights is \"common voice 20240306\"\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'small_df_jahalt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimal_example_results_fast.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pfile:\n\u001b[1;32m     10\u001b[0m         pickle\u001b[38;5;241m.\u001b[39mdump((results), pfile)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtest_paule_fast\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m, in \u001b[0;36mtest_paule_fast\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_paule_fast\u001b[39m():\n\u001b[0;32m----> 7\u001b[0m     results \u001b[38;5;241m=\u001b[39m score(synth_baseline_segment, preloaded_data\u001b[38;5;241m=\u001b[39m\u001b[43msmall_df_jahalt\u001b[49m[:\u001b[38;5;241m10\u001b[39m], tasks\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, subscores\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m, return_individual_subscores\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      8\u001b[0m                     )\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimal_example_results_fast.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m pfile:\n\u001b[1;32m     10\u001b[0m         pickle\u001b[38;5;241m.\u001b[39mdump((results), pfile)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'small_df_jahalt' is not defined"
     ]
    }
   ],
   "source": [
    "from articubench.score import score\n",
    "from articubench.control_models import synth_paule_fast, synth_baseline_schwa, synth_paule_acoustic_semvec, synth_baseline_segment\n",
    "import pickle\n",
    "\n",
    "def test_paule_fast():\n",
    "\n",
    "    results = score(synth_baseline_segment, preloaded_data=small_df_jahalt[:10], tasks='all', subscores='all', return_individual_subscores=True\n",
    "                    )\n",
    "    with open('minimal_example_results_fast.pkl', 'wb') as pfile:\n",
    "        pickle.dump((results), pfile)\n",
    "\n",
    "test_paule_fast()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GoodVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
